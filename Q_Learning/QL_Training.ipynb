{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomadic_trucker_new import nomadictrucker\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import scipy\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pickle\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_action(Q, state, epsilon):\n",
    "\n",
    "    actions = model['all_actions']\n",
    "    best_action = np.argmax(Q[state]) # best action with highest Q value\n",
    "    random_action = np.random.choice(actions)\n",
    "    next_action = np.random.choice([best_action, random_action], p = [(1-epsilon),epsilon])\n",
    "\n",
    "    return next_action\n",
    "\n",
    "def qLearning(num_episodes, discount_factor = 0.95, alpha = 0.2, epsilon = 0.1):\n",
    "\n",
    "    Q = defaultdict(lambda:np.zeros(len(model['all_actions'])))\n",
    "    all_episode_rewards = np.zeros(num_episodes)\n",
    "    all_episode_lengths = np.zeros(num_episodes)\n",
    "\n",
    "    np.set_printoptions(precision = 2)\n",
    "    visited_states=[]\n",
    "    for ith_episode in range(num_episodes):\n",
    "#         print('episode:', ith_episode)\n",
    "\n",
    "        # Reset the environment and pick the first action\n",
    "        state_index = model['get_first_state']()\n",
    "\n",
    "        previous_state = state_index\n",
    "\n",
    "        visited_states.append(state_index)\n",
    "\n",
    "        loaded_moves = 0\n",
    "\n",
    "        for t in itertools.count():\n",
    "\n",
    "            #action = # get action\n",
    "            action = get_next_action(Q, state_index, epsilon)\n",
    "\n",
    "            load = model['get_state_exp'](state_index)[3]\n",
    "            if load[action] == 1:\n",
    "                loaded_moves += 1\n",
    "\n",
    "\n",
    "            # take action and get reward, transit to next state\n",
    "            next_truck_location = model['get_actual_next_grid_state'](action, state_index)[0]\n",
    "            next_day = model['get_actual_next_grid_state'](action, state_index)[1]\n",
    "            next_trailer_type = model['get_actual_next_grid_state'](action,state_index)[2]\n",
    "            new_load = model['get_actual_next_grid_state'](action, state_index)[3]\n",
    "            next_state = model['get_numeric_state_nomadic_trucker'](next_truck_location, next_day, next_trailer_type, new_load)\n",
    "            #print(new_load)\n",
    "            reward = model['get_rewards'](state_index, action)\n",
    "\n",
    "            # Update statistics\n",
    "            all_episode_rewards[ith_episode] += reward\n",
    "            all_episode_lengths[ith_episode] = t\n",
    "\n",
    "            # TD Update\n",
    "\n",
    "            best_next_action = np.argmax(Q[next_state])\n",
    "            td_target = reward + discount_factor * (Q[next_state][best_next_action])\n",
    "            td_delta = td_target - (Q[state_index][action])\n",
    "            (Q[state_index][action]) +=(alpha * td_delta)\n",
    "\n",
    "            if loaded_moves == 10: # end after 100 days\n",
    "#                 print(\"{}th episode is finished with delta: {}!\".format(ith_episode, td_delta))\n",
    "                break\n",
    "            previous_state = state_index\n",
    "            state_index = next_state\n",
    "            if state_index not in visited_states:\n",
    "                visited_states.append(state_index)\n",
    "    return Q, all_episode_rewards, all_episode_lengths, visited_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible states\n",
    "s = [2, 3]\n",
    "\n",
    "# possible days\n",
    "d = [1, 3, 7]\n",
    "\n",
    "# possible trailer types\n",
    "t = [1, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "64 time: 35.59246611595154\n",
      "done state space size: 64\n",
      "1000\n",
      "576 time: 50.452276945114136\n",
      "done state space size: 576\n",
      "1000\n",
      "1344 time: 69.52126502990723\n",
      "done state space size: 1344\n",
      "10000\n",
      "4608 time: 389.6080241203308\n",
      "done state space size: 4608\n",
      "10000\n",
      "41472 time: 539.1700129508972\n",
      "done state space size: 41472\n",
      "10000\n",
      "96768 time: 773.6231310367584\n",
      "done state space size: 96768\n"
     ]
    }
   ],
   "source": [
    "for size in s:\n",
    "    for days, trailers in zip(d,t):\n",
    "        model = nomadictrucker(size,days,trailers)\n",
    "        if size == 3:\n",
    "            n = 10000\n",
    "        else:\n",
    "            n = 1000\n",
    "        \n",
    "        start = time.time()\n",
    "        Q_val, all_episode_rewards, all_episode_lengths, visited_states = qLearning(n)\n",
    "        end = time.time()\n",
    "        print(n)\n",
    "        print(str(len(model[\"states\"])),\"time:\", (end - start))\n",
    "        with open(\"visited_states_nomadic_\"+str(size)+\"_\"+str(days)+\"d_\"+str(trailers)+\"t.pickle\",\"wb\") as fp:\n",
    "            pickle.dump(visited_states, fp)\n",
    "        with open(\"Q_nomadic_\"+str(size)+\"_\"+str(days)+\"d_\"+str(trailers)+\"t.pickle\",\"wb\") as fp:\n",
    "            pickle.dump(dict(Q_val), fp)\n",
    "        print(\"done state space size:\", str(len(model[\"states\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
